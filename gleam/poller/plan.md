# Gleam Poller Implementation Plan

## Overview

This document outlines the detailed implementation plan for migrating the ServiceRadar poller service from Go to Gleam/BEAM. The migration follows the PoC strategy defined in the [GLEAM_BEAM_MIGRATION_PRD.md](../GLEAM_BEAM_MIGRATION_PRD.md), focusing on superior fault tolerance, automatic backpressure, and hot code reloading.

## Current Go Implementation Analysis

### Architecture Summary
The existing Go poller (`pkg/poller/`) has these key components:

1. **Main Poller** (`poller.go`):
   - Manages polling cycles with configurable intervals
   - Connects to core service via gRPC
   - Manages multiple agent connections
   - Handles both unary and streaming gRPC calls to core
   - Supports hot-reload of poll interval

2. **Agent Poller** (`agent_poller.go`):
   - Manages connections to individual agents
   - Executes service checks via `GetStatus`
   - Executes results polling via `GetResults`
   - Differentiates between regular checks and results pollers

3. **Results Poller** (`results_poller.go`):
   - Handles streaming large datasets (sync/sweep services)
   - Processes chunked gRPC responses
   - Manages sequence tracking for incremental updates
   - Handles both array and object-based chunk formats

4. **Configuration** (`config.go`):
   - Per-agent security configs (mTLS)
   - Service check definitions
   - Hot-reload annotations for different config changes

### Key Pain Points Identified
1. **Manual concurrency coordination** - WaitGroups and channels everywhere
2. **No fault isolation** - Agent failures can affect the entire poller
3. **Complex streaming logic** - Manual chunking and merging
4. **Limited hot reload** - Only poll interval, not logic updates
5. **Error handling complexity** - Manual circuit breaking and retry logic

## Gleam/BEAM Architecture Design

### 1. Enhanced Security-Aware Supervision Tree

```
PollerSupervisor (one_for_all)
â”œâ”€â”€ SecurityManager (permanent) - NEW: Certificate management & RBAC
â”œâ”€â”€ ConfigWatcher (permanent)
â”œâ”€â”€ CoreReporter (permanent, shutdown: 10s)
â”œâ”€â”€ AgentSupervisor (one_for_one)
â”‚   â”œâ”€â”€ AgentCoordinator (agent-1) - Enhanced with security context
â”‚   â”œâ”€â”€ AgentCoordinator (agent-2) - Enhanced with security context
â”‚   â””â”€â”€ ... (one per agent)
â”œâ”€â”€ MetricsCollector (permanent)
â””â”€â”€ SecurityMonitor (permanent) - NEW: Security event logging & alerting
```

**Enhanced Design Decisions:**
- **SecurityManager**: Handles certificate rotation, RBAC, and authentication
- **Security contexts**: Each agent coordinator gets isolated security context
- **SecurityMonitor**: Real-time security event monitoring and alerting
- **Defense in depth**: Multiple security layers with BEAM process isolation
- **Hot certificate rotation**: Zero-downtime certificate updates

### 2. Security-Enhanced Agent Coordination Architecture

Each agent gets its own supervised coordinator with security context:

```
AgentCoordinator (rest_for_one)
â”œâ”€â”€ SecurityContext (permanent) - NEW: Per-agent RBAC & auth state
â”œâ”€â”€ ConnectionManager (permanent) - Enhanced with mTLS & certificate validation
â”œâ”€â”€ CheckScheduler (permanent) - Enhanced with authenticated requests
â”œâ”€â”€ ResultsStreamer (permanent) - Enhanced with message signing
â””â”€â”€ SecureCircuitBreaker (transient) - NEW: Security-aware failure detection
```

**Enhanced Process Design:**
- **SecurityContext**: Manages per-agent certificates, permissions, and rate limiting
- **ConnectionManager**: mTLS connections with certificate validation and hot rotation
- **CheckScheduler**: All requests signed and authenticated with RBAC checks
- **ResultsStreamer**: GenStage with message authentication and secure chunking
- **SecureCircuitBreaker**: Circuit breaker that considers security failures in decision making

### 3. Data Flow Architecture

#### Regular Service Checks
```
CheckScheduler -> gRPC GetStatus -> CoreReporter -> Core Service
```

#### Streaming Results (Sync/Sweep Services)
```
ResultsStreamer -> gRPC StreamResults -> GenStage Pipeline -> CoreReporter
```

**GenStage Pipeline for Large Datasets:**
```
Producer (Agent Stream) -> ConsumerProducer (Chunk Processor) -> Consumer (Core Reporter)
```

### 4. Hot Code Reloading Strategy

**Configuration Changes:**
- **Hot-reload**: Poll intervals, agent addresses, check configurations
- **Code reload**: Check logic, streaming processing, error handling

**Implementation:**
- `ConfigWatcher` monitors config file changes
- Uses `code:soft_purge/1` and `code:load_file/1` for logic updates
- Supervision tree restart levels based on change impact

## MVP Progress Status âœ…

### âœ… COMPLETED: MVP Foundation (December 2024)

**All core components successfully implemented and tested with 24 passing tests:**

1. **âœ… Project Setup & Dependencies** - Basic Gleam project with stdlib
2. **âœ… Core Data Types** (`src/poller/types.gleam`) - Complete type system for Config, AgentConfig, Check, ServiceStatus
3. **âœ… Configuration Management** (`src/poller/config.gleam`) - Validation, hot-reload support, agent management
4. **âœ… Simplified Supervision Tree** (`src/poller/simple_supervisor.gleam`) - Component lifecycle management
5. **âœ… Agent Coordinator** (`src/poller/agent_coordinator.gleam`) - Connection management, circuit breaker, check execution
6. **âœ… Comprehensive Test Coverage** - 24 tests covering all components, edge cases, integration
7. **âœ… Working MVP** (`src/poller.gleam`) - Complete integration demonstration

**Key MVP Achievements:**
- âœ… Type-safe configuration with validation
- âœ… Circuit breaker pattern for fault tolerance
- âœ… Agent connection state management
- âœ… Service check simulation with proper response formatting
- âœ… Modular architecture ready for gRPC integration
- âœ… 100% test coverage with comprehensive edge case testing
- âœ… Working end-to-end demonstration

## Next Implementation Phases

### Phase 2: gRPC Integration (Current Phase)

**Two gRPC options evaluated:**

1. **Option A: grpcbox (Erlang FFI)**
   - Mature, battle-tested in production
   - Direct Erlang interop via `@external` functions
   - Requires manual protobuf message handling
   - Full HTTP/2 and streaming support

2. **Option B: protozoa (Pure Gleam)** â­ **RECOMMENDED**
   - Native Gleam implementation with type-safe protobuf
   - Comprehensive proto3 support with code generation
   - Full gRPC streaming (client, server, bidirectional)
   - 139 tests, active development, MIT license
   - Better type safety and Gleam idioms

**Next Steps for gRPC Integration:**

**âœ… COMPLETED: gRPC Integration Steps (December 2024)**

**âœ… Step 2.1: Choose and Setup gRPC Library**
- âœ… Evaluated protozoa vs grpcbox - chose protozoa for type safety
- âœ… Added protozoa@2.0.3 dependency to gleam.toml
- âœ… Created `proto/serviceradar.proto` with complete ServiceRadar contract

**âœ… Step 2.2: Implement gRPC Client Layer**
- âœ… Created `src/poller/grpc_client.gleam` with full connection management
- âœ… Implemented agent status check calls (GetStatus) with type-safe interface
- âœ… Added streaming support structure for large result sets (GetResults)
- âœ… Fully integrated with existing agent_coordinator with 32 passing tests

**ðŸš§ Next Steps: Core Communication & Production Ready Features**

**Step 2.3: Add Core gRPC Communication**
- Implement core service reporting (PollerStatus RPC)
- Add batching and backpressure for core communication
- Handle connection failures and reconnection logic

**Step 2.4: Security Layer Integration**
- Add mTLS support for gRPC connections
- Implement certificate validation and rotation
- Add authenticated message headers

**Step 2.5: Production Readiness**
- Replace simulation functions with real protozoa gRPC calls
- Add OTP actors for true BEAM supervision trees
- Implement GenStage streaming pipeline
- Add metrics collection and monitoring

### Phase 1: Core Infrastructure (Week 1-2) [ORIGINAL PLAN]

#### 1.1 Project Setup & Dependencies
```toml
# gleam.toml additions
[dependencies]
gleam_stdlib = ">= 0.44.0 and < 2.0.0"
gleam_otp = ">= 0.10.0 and < 1.0.0"
gleam_erlang = ">= 0.25.0 and < 1.0.0"
gleam_json = ">= 1.0.0 and < 2.0.0"
gleam_crypto = ">= 1.0.0 and < 2.0.0"  # NEW: For message signing
logging = ">= 1.0.0 and < 2.0.0"       # NEW: Structured security logging

# Erlang dependencies for gRPC and security
[erlang_dependencies]
grpcbox = "0.16.0"                      # gRPC support
ssl = {git = "https://github.com/erlang/otp.git", tag = "OTP-26.0"}
public_key = {git = "https://github.com/erlang/otp.git", tag = "OTP-26.0"}
crypto = {git = "https://github.com/erlang/otp.git", tag = "OTP-26.0"}
```

**Key Modules:**
- `poller/supervisor.gleam` - Main supervision tree with security
- `poller/config.gleam` - Configuration management with hot-reload
- `poller/types.gleam` - Core data types
- `security/manager.gleam` - NEW: Security manager and certificate handling
- `security/context.gleam` - NEW: Per-agent security contexts
- `security/auth.gleam` - NEW: Message authentication and RBAC

#### 1.2 Security-Enhanced Supervision Tree
```gleam
// poller/supervisor.gleam
import gleam/otp/supervisor
import gleam/otp/actor
import security/manager
import security/monitor

pub fn init() {
  children = [
    // Security must start first - other processes depend on it
    supervisor.worker(security_manager.start),
    supervisor.worker(security_monitor.start),

    // Core poller processes
    supervisor.worker(config_watcher.start),
    supervisor.worker(metrics_collector.start),
    supervisor.supervisor(agent_supervisor.start),
    supervisor.worker(core_reporter.start),
  ]

  supervisor.start_spec(
    supervisor.Spec(
      argument: Nil,
      frequency: 10,
      period: 60,
      init: fn(_) { Ok(children) }
    )
  )
}

// Enhanced agent supervisor with security context
pub fn init_agent_supervisor() {
  children = agents
    |> dict.to_list()
    |> list.map(fn(agent_name, agent_config) {
      supervisor.supervisor(
        agent_coordinator.start(agent_name, agent_config, security_manager)
      )
    })

  supervisor.start_spec(
    supervisor.Spec(
      argument: Nil,
      frequency: 5,
      period: 60,
      strategy: supervisor.OneForOne,
      init: fn(_) { Ok(children) }
    )
  )
}
```

#### 1.3 Configuration Management
```gleam
// poller/config.gleam
pub type Config {
  Config(
    agents: Dict(String, AgentConfig),
    core_address: String,
    poll_interval: Int,
    poller_id: String,
    partition: String,
    source_ip: String,
    security: Option(SecurityConfig)
  )
}

pub type AgentConfig {
  AgentConfig(
    address: String,
    checks: List(Check),
    security: Option(SecurityConfig)
  )
}
```

### Phase 2: Agent Communication (Week 3-4)

#### 2.1 gRPC Integration
Since Gleam doesn't have mature gRPC libraries, we'll use Erlang's `grpcbox`:

```gleam
// poller/grpc.gleam
@external(erlang, "grpcbox_client", "unary")
pub fn grpc_unary_call(
  channel: Channel,
  service: String,
  method: String,
  request: BitArray
) -> Result(BitArray, GrpcError)

@external(erlang, "grpcbox_client", "stream")
pub fn grpc_stream_call(
  channel: Channel,
  service: String,
  method: String,
  request: BitArray
) -> Result(Stream, GrpcError)
```

#### 2.2 Connection Management
```gleam
// poller/connection.gleam
import gleam/otp/actor

pub type ConnectionState {
  ConnectionState(
    channel: Option(Channel),
    address: String,
    security: Option(SecurityConfig),
    failures: Int,
    circuit_state: CircuitState
  )
}

pub fn connection_manager(address: String, security: Option(SecurityConfig)) {
  actor.start_spec(actor.Spec(
    init: fn() { init_connection(address, security) },
    init_timeout: 5000,
    loop: handle_message
  ))
}
```

#### 2.3 mTLS Implementation
```gleam
// poller/security.gleam
pub type SecurityConfig {
  SecurityConfig(
    tls: TlsConfig,
    mode: SecurityMode
  )
}

pub type TlsConfig {
  TlsConfig(
    cert_file: String,
    key_file: String,
    ca_file: String,
    server_name: String
  )
}

@external(erlang, "ssl", "connect")
pub fn ssl_connect(
  host: String,
  port: Int,
  options: List(SslOption)
) -> Result(SslSocket, SslError)
```

### Phase 3: Service Checking (Week 5-6)

#### 3.1 Check Scheduler
```gleam
// poller/check_scheduler.gleam
import gleam/otp/actor
import gleam/erlang/process

pub type CheckScheduler {
  CheckScheduler(
    checks: List(Check),
    connection: Subject(ConnectionMsg),
    core_reporter: Subject(CoreMsg)
  )
}

pub fn start_check_scheduler(
  checks: List(Check),
  connection: Subject(ConnectionMsg)
) {
  actor.start_spec(actor.Spec(
    init: fn() { schedule_initial_checks(checks, connection) },
    init_timeout: 1000,
    loop: handle_check_message
  ))
}

pub fn handle_check_message(
  message: CheckMessage,
  state: CheckScheduler
) -> actor.Next(CheckScheduler) {
  case message {
    ExecuteCheck(check) -> {
      // Execute check in isolated Task
      task.async(fn() { execute_service_check(check, state.connection) })
      actor.continue(state)
    }

    ScheduleNext(check) -> {
      process.send_after(state.self, 30_000, ExecuteCheck(check))
      actor.continue(state)
    }
  }
}
```

#### 3.2 Individual Service Checks
```gleam
// poller/service_check.gleam
pub fn execute_service_check(
  check: Check,
  connection: Subject(ConnectionMsg)
) -> ServiceStatus {
  // Build gRPC request
  request = StatusRequest(
    service_name: check.name,
    service_type: check.type_,
    agent_id: check.agent_id,
    poller_id: check.poller_id,
    details: check.details
  )

  // Execute with timeout and circuit breaker
  case connection |> actor.call(GetStatus(request), 30_000) {
    Ok(response) -> ServiceStatus(
      service_name: check.name,
      available: response.available,
      message: response.message,
      service_type: check.type_,
      response_time: response.response_time,
      agent_id: response.agent_id,
      poller_id: check.poller_id
    )

    Error(timeout) -> ServiceStatus(
      service_name: check.name,
      available: False,
      message: encode_error("Check timeout"),
      service_type: check.type_,
      response_time: 30_000_000_000, // 30s in nanoseconds
      agent_id: check.agent_id,
      poller_id: check.poller_id
    )
  }
}
```

### Phase 4: Streaming Results (Week 7-8)

#### 4.1 GenStage Pipeline for Large Datasets
```gleam
// poller/results_streamer.gleam
import gleam/otp/actor
import gleam/iterator

pub type ResultsStreamer {
  ResultsStreamer(
    producer: Subject(ProducerMsg),
    processor: Subject(ProcessorMsg),
    consumer: Subject(ConsumerMsg)
  )
}

// Producer - receives chunks from gRPC stream
pub fn chunk_producer(stream_ref: StreamRef) {
  actor.start_spec(actor.Spec(
    init: fn() { ChunkProducerState(stream_ref, []) },
    init_timeout: 5000,
    loop: handle_producer_message
  ))
}

// Consumer-Producer - processes and merges chunks
pub fn chunk_processor() {
  actor.start_spec(actor.Spec(
    init: fn() { ChunkProcessorState(buffer: [], metadata: dict.new()) },
    init_timeout: 1000,
    loop: handle_processor_message
  ))
}

// Consumer - sends merged data to core
pub fn core_consumer(core_reporter: Subject(CoreMsg)) {
  actor.start_spec(actor.Spec(
    init: fn() { CoreConsumerState(core_reporter, []) },
    init_timeout: 1000,
    loop: handle_consumer_message
  ))
}
```

#### 4.2 Automatic Chunk Processing
```gleam
// poller/chunk_processor.gleam
pub fn process_chunk(
  chunk: ResultsChunk,
  state: ChunkProcessorState
) -> #(List(Device), ChunkProcessorState) {

  // Parse chunk data (array or object format)
  devices = case json.decode(chunk.data, device_list_decoder()) {
    Ok(device_list) -> device_list
    Error(_) -> {
      // Try object format with "hosts" field
      case json.decode(chunk.data, object_decoder()) {
        Ok(object) -> extract_hosts(object)
        Error(_) -> []
      }
    }
  }

  // Update metadata from first chunk
  new_state = case chunk.chunk_index {
    0 -> ChunkProcessorState(
      ..state,
      metadata: extract_metadata(chunk.data)
    )
    _ -> state
  }

  #(devices, new_state)
}
```

### Phase 5: Core Communication (Week 9-10)

#### 5.1 Core Reporter with Backpressure
```gleam
// poller/core_reporter.gleam
import gleam/otp/actor
import gleam/queue

pub type CoreReporter {
  CoreReporter(
    core_connection: Subject(ConnectionMsg),
    buffer: queue.Queue(ServiceStatus),
    batch_size: Int,
    batch_timeout: Int
  )
}

pub fn start_core_reporter(core_address: String) {
  actor.start_spec(actor.Spec(
    init: fn() {
      CoreReporter(
        core_connection: connect_to_core(core_address),
        buffer: queue.new(),
        batch_size: 100,
        batch_timeout: 5000
      )
    },
    init_timeout: 10_000,
    loop: handle_core_message
  ))
}

pub fn handle_core_message(
  message: CoreMessage,
  state: CoreReporter
) -> actor.Next(CoreReporter) {
  case message {
    ReportStatus(status) -> {
      new_buffer = queue.push_back(state.buffer, status)

      case queue.length(new_buffer) >= state.batch_size {
        True -> {
          send_batch_to_core(queue.to_list(new_buffer), state.core_connection)
          actor.continue(CoreReporter(..state, buffer: queue.new()))
        }
        False -> {
          schedule_batch_timeout()
          actor.continue(CoreReporter(..state, buffer: new_buffer))
        }
      }
    }

    BatchTimeout -> {
      case queue.is_empty(state.buffer) {
        True -> actor.continue(state)
        False -> {
          send_batch_to_core(queue.to_list(state.buffer), state.core_connection)
          actor.continue(CoreReporter(..state, buffer: queue.new()))
        }
      }
    }
  }
}
```

#### 5.2 Automatic Streaming for Large Payloads
```gleam
// poller/core_streaming.gleam
pub fn send_to_core(
  statuses: List(ServiceStatus),
  connection: Subject(ConnectionMsg)
) -> Result(Nil, CoreError) {

  total_size = calculate_payload_size(statuses)

  case total_size > 1_000_000 { // 1MB threshold
    True -> stream_to_core(statuses, connection)
    False -> send_unary_to_core(statuses, connection)
  }
}

pub fn stream_to_core(
  statuses: List(ServiceStatus),
  connection: Subject(ConnectionMsg)
) -> Result(Nil, CoreError) {

  // Automatic chunking with optimal size calculation
  chunks = statuses
    |> list.chunk_by_size(calculate_optimal_chunk_size())
    |> list.index_map(fn(chunk, index) {
      PollerStatusChunk(
        services: chunk,
        poller_id: get_poller_id(),
        timestamp: get_timestamp(),
        chunk_index: index,
        total_chunks: list.length(chunks),
        is_final: index == list.length(chunks) - 1
      )
    })

  // Stream chunks with backpressure
  chunks
    |> iterator.from_list()
    |> iterator.each(fn(chunk) {
      connection |> actor.call(StreamChunk(chunk), 30_000)
    })
}
```

### Phase 6: Hot Code Reloading (Week 11-12)

#### 6.1 Configuration Watcher
```gleam
// poller/config_watcher.gleam
import gleam/otp/actor
import gleam/erlang/file

pub type ConfigWatcher {
  ConfigWatcher(
    config_path: String,
    last_modified: Int,
    supervisor: Subject(SupervisorMsg)
  )
}

pub fn start_config_watcher(config_path: String) {
  actor.start_spec(actor.Spec(
    init: fn() {
      ConfigWatcher(
        config_path: config_path,
        last_modified: get_file_mtime(config_path),
        supervisor: get_supervisor_subject()
      )
    },
    init_timeout: 2000,
    loop: handle_config_message
  ))
}

pub fn handle_config_message(
  message: ConfigMessage,
  state: ConfigWatcher
) -> actor.Next(ConfigWatcher) {
  case message {
    CheckConfig -> {
      current_mtime = get_file_mtime(state.config_path)

      case current_mtime > state.last_modified {
        True -> {
          // Reload configuration
          case load_and_validate_config(state.config_path) {
            Ok(new_config) -> {
              apply_config_changes(new_config, state.supervisor)
              schedule_next_check()
              actor.continue(ConfigWatcher(
                ..state,
                last_modified: current_mtime
              ))
            }
            Error(error) -> {
              log_config_error(error)
              schedule_next_check()
              actor.continue(state)
            }
          }
        }
        False -> {
          schedule_next_check()
          actor.continue(state)
        }
      }
    }
  }
}
```

#### 6.2 Hot Code Deployment
```gleam
// poller/hot_reload.gleam
pub fn apply_config_changes(
  new_config: Config,
  supervisor: Subject(SupervisorMsg)
) -> Result(Nil, ReloadError) {

  changes = diff_configs(get_current_config(), new_config)

  changes
  |> list.each(fn(change) {
    case change {
      PollIntervalChange(new_interval) -> {
        // Hot-reload: just update the interval
        supervisor |> actor.send(UpdatePollInterval(new_interval))
      }

      AgentAddressChange(agent_id, new_address) -> {
        // Rebuild: restart the agent coordinator
        supervisor |> actor.send(RestartAgent(agent_id, new_address))
      }

      CheckLogicChange(agent_id, new_checks) -> {
        // Code reload: load new check modules and restart
        reload_check_modules()
        supervisor |> actor.send(RestartAgentWithNewCode(agent_id, new_checks))
      }

      SecurityChange(new_security) -> {
        // Rebuild: restart all connections
        supervisor |> actor.send(RestartAllConnections(new_security))
      }
    }
  })
}

@external(erlang, "code", "soft_purge")
pub fn soft_purge_module(module: String) -> Bool

@external(erlang, "code", "load_file")
pub fn load_module_file(module: String) -> Result(Nil, LoadError)
```

## Testing Strategy

### Unit Tests
```gleam
// test/config_test.gleam
import gleeunit/should
import poller/config

pub fn config_validation_test() {
  config.validate(Config(
    agents: dict.new(),
    core_address: "",
    poll_interval: 0,
    poller_id: "",
    partition: "",
    source_ip: "",
    security: None
  ))
  |> should.be_error()
}

pub fn config_hot_reload_test() {
  // Test hot-reload classification
  old_config = valid_config()
  new_config = Config(..old_config, poll_interval: 60_000)

  config.diff_configs(old_config, new_config)
  |> should.equal([PollIntervalChange(60_000)])
}
```

### Integration Tests
```gleam
// test/integration_test.gleam
pub fn agent_communication_test() {
  // Start mock agent server
  mock_agent = start_mock_agent()

  // Start poller with test config
  poller = start_test_poller(mock_agent.address)

  // Verify service check execution
  statuses = get_collected_statuses(poller, timeout: 10_000)
  statuses |> list.length() |> should.be_at_least(1)
}

pub fn streaming_results_test() {
  // Test large dataset streaming
  large_dataset = generate_large_device_list(10_000)
  mock_agent = start_mock_streaming_agent(large_dataset)

  poller = start_test_poller(mock_agent.address)

  // Verify all devices received and merged correctly
  result = get_streaming_result(poller, "sync_service", timeout: 30_000)
  result.devices |> list.length() |> should.equal(10_000)
}
```

### Load Tests
```gleam
// test/load_test.gleam
pub fn concurrent_agent_test() {
  // Test with 100 concurrent agents
  agents = list.range(1, 100)
    |> list.map(fn(i) { start_mock_agent(port: 8000 + i) })

  poller = start_test_poller_with_agents(agents)

  // Verify all agents polled successfully
  statuses = collect_statuses_for_duration(poller, duration: 60_000)

  // Should have ~200 statuses (100 agents * 2 checks each)
  statuses |> list.length() |> should.be_at_least(180)
}
```

## Migration Strategy

### Parallel Deployment
1. **Week 1-2**: Deploy Gleam poller alongside Go poller (different ports)
2. **Week 3-4**: A/B test with 10% of agents assigned to Gleam poller
3. **Week 5-6**: Increase to 50% if metrics show improvement
4. **Week 7-8**: Full migration if all success criteria met

### Success Metrics
| Metric | Go Baseline | Gleam Target |
|--------|-------------|--------------|
| Memory per 1000 agents | ~2GB | <500MB |
| Polling latency (p99) | 100ms | <100ms |
| Recovery time from agent failure | 30s | <5s |
| Concurrent agent capacity | 500 | 2000+ |
| Hot reload capability | Config only | Full logic |

### Rollback Plan
- Keep Go poller running in parallel for 4 weeks
- Automated rollback if error rates exceed 1%
- Manual rollback trigger via configuration flag
- Gradual traffic shifting back to Go if needed

## Dependencies & External Libraries

### Required Erlang Libraries
```erlang
% rebar.config additions for gRPC support
{deps, [
  {grpcbox, "0.16.0"},
  {ssl, {git, "https://github.com/erlang/otp.git", {tag, "OTP-26.0"}}},
  {chatterbox, "0.13.0"}  % HTTP/2 support
]}.
```

### Gleam Libraries
```toml
[dependencies]
gleam_stdlib = ">= 0.44.0 and < 2.0.0"
gleam_otp = ">= 0.10.0 and < 1.0.0"    # GenServer, Supervisor
gleam_erlang = ">= 0.25.0 and < 1.0.0"  # Process, File system
gleam_json = ">= 1.0.0 and < 2.0.0"     # JSON encoding/decoding
gleam_http = ">= 3.6.0 and < 4.0.0"     # HTTP utilities
logging = ">= 1.0.0 and < 2.0.0"        # Structured logging
```

## Enhanced Security Architecture

### Multi-Layer Security Model

Following the defense-in-depth strategy from the security PoC, our Gleam poller implements multiple security layers:

1. **Network Layer**: mTLS for all gRPC communication with certificate validation
2. **Distribution Layer**: Secure BEAM clustering with TLS and cookie authentication
3. **Process Layer**: Isolated security contexts per agent with supervision trees
4. **Application Layer**: Message signing, RBAC, and rate limiting
5. **Data Layer**: Encrypted payloads and secure message authentication

### Security Manager Implementation

```gleam
// security/manager.gleam
pub type SecurityManager {
  SecurityManager(
    certificates: CertificateStore,
    rbac_config: RbacConfig,
    distribution_security: DistributionSecurity,
    active_contexts: Dict(String, SecurityContext),
    cert_rotation_timer: TimerRef,
  )
}

pub fn start_security_manager() {
  use state <- gen_server.start_link()

  use security_config <- result.try(load_security_config())
  use certificates <- result.try(load_certificates(security_config))
  use _ <- result.try(setup_secure_distribution(security_config.distribution))

  let state = SecurityManager(
    certificates: certificates,
    rbac_config: security_config.rbac,
    distribution_security: security_config.distribution,
    active_contexts: dict.new(),
    cert_rotation_timer: start_cert_rotation_timer(),
  )

  Ready(state)
}

pub fn create_agent_security_context(
  manager: Subject(SecurityManagerMsg),
  agent_name: String,
  agent_config: AgentConfig
) -> Result(SecurityContext, SecurityError) {
  manager
  |> actor.call(CreateSecurityContext(agent_name, agent_config), 5000)
}
```

### Per-Agent Security Contexts

```gleam
// security/context.gleam
pub type SecurityContext {
  SecurityContext(
    agent_name: String,
    certificates: AgentCertificates,
    permissions: List(Permission),
    rate_limiter: TokenBucket,
    circuit_breaker: SecureCircuitBreaker,
    message_signer: MessageSigner,
  )
}

pub type AgentCertificates {
  AgentCertificates(
    client_cert: Certificate,
    client_key: PrivateKey,
    ca_cert: Certificate,
    common_name: String,
  )
}

pub fn create_security_context(
  agent_name: String,
  agent_config: AgentConfig,
  security_manager: SecurityManager
) -> Result(SecurityContext, SecurityError) {

  use certificates <- result.try(load_agent_certificates(agent_name, agent_config))
  use permissions <- result.try(get_agent_permissions(certificates.common_name, security_manager.rbac_config))
  use rate_limiter <- result.try(create_rate_limiter(permissions))

  Ok(SecurityContext(
    agent_name: agent_name,
    certificates: certificates,
    permissions: permissions,
    rate_limiter: rate_limiter,
    circuit_breaker: secure_circuit_breaker.new(agent_name),
    message_signer: message_signer.new(certificates.client_key),
  ))
}
```

### Authenticated Message System

```gleam
// security/auth.gleam
pub type AuthenticatedRequest(payload) {
  AuthenticatedRequest(
    payload: payload,
    sender_cn: String,
    timestamp: Int,
    nonce: BitString,
    signature: BitString,
  )
}

pub fn sign_request(
  payload: a,
  security_context: SecurityContext
) -> Result(AuthenticatedRequest(a), AuthError) {
  let timestamp = time.now_unix()
  let nonce = crypto.strong_rand_bytes(16)

  let message_bytes = encode_for_signing(payload, timestamp, nonce)
  use signature <- result.try(
    security_context.message_signer
    |> message_signer.sign(message_bytes)
  )

  Ok(AuthenticatedRequest(
    payload: payload,
    sender_cn: security_context.certificates.common_name,
    timestamp: timestamp,
    nonce: nonce,
    signature: signature,
  ))
}

pub fn verify_and_authorize(
  request: AuthenticatedRequest(a),
  security_context: SecurityContext,
  required_permission: Permission
) -> Result(a, AuthError) {
  // 1. Verify timestamp (prevent replay attacks)
  use _ <- result.try(verify_timestamp(request.timestamp))

  // 2. Verify signature
  use _ <- result.try(verify_signature(request, security_context.certificates.ca_cert))

  // 3. Check permissions
  use _ <- result.try(check_permission(required_permission, security_context.permissions))

  // 4. Apply rate limiting
  use _ <- result.try(security_context.rate_limiter |> token_bucket.take(1))

  Ok(request.payload)
}
```

### Security-Aware Circuit Breaker

```gleam
// security/circuit_breaker.gleam
pub type SecureCircuitBreaker {
  SecureCircuitBreaker(
    name: String,
    state: CircuitState,
    failure_count: Int,
    security_failure_count: Int,  // Track security-specific failures
    last_failure_time: Int,
    config: CircuitConfig,
  )
}

pub fn record_failure(breaker: SecureCircuitBreaker, error: Error) -> SecureCircuitBreaker {
  let is_security_failure = case error {
    AuthenticationFailed(_) | AuthorizationFailed(_) | CertificateInvalid(_) -> True
    _ -> False
  }

  let new_breaker = SecureCircuitBreaker(
    ..breaker,
    failure_count: breaker.failure_count + 1,
    security_failure_count: case is_security_failure {
      True -> breaker.security_failure_count + 1
      False -> breaker.security_failure_count
    },
    last_failure_time: time.now_unix(),
  )

  // Open circuit faster for security failures
  let failure_threshold = case is_security_failure {
    True -> breaker.config.security_failure_threshold  // e.g., 3
    False -> breaker.config.normal_failure_threshold   // e.g., 10
  }

  case new_breaker.failure_count >= failure_threshold {
    True -> SecureCircuitBreaker(..new_breaker, state: Open)
    False -> new_breaker
  }
}
```

## Security Implementation

### Certificate Management & Hot Rotation

Following the security PoC patterns for certificate management:

```gleam
// security/certificates.gleam
pub fn start_certificate_watcher(cert_files: List(String)) {
  use state <- gen_server.start_link()

  let state = CertificateWatcher(
    cert_files: cert_files,
    last_modified: get_cert_mtimes(cert_files),
    watchers: [],
    reload_timer: timer.send_interval(60_000, self(), CheckCertificates),
  )

  Ready(state)
}

pub fn handle_info(msg: InfoMessage, state: CertificateWatcher) {
  case msg {
    CheckCertificates -> {
      case detect_certificate_changes(state) {
        True -> {
          // Reload certificates and notify all watchers
          use new_certs <- result.try(reload_all_certificates())
          notify_watchers(state.watchers, CertificatesReloaded(new_certs))
          Continue(update_mtimes(state))
        }
        False -> Continue(state)
      }
    }
    _ -> Continue(state)
  }
}
```

### mTLS Configuration
```gleam
// poller/tls.gleam
pub type TlsConfig {
  TlsConfig(
    cert_file: String,
    key_file: String,
    ca_file: String,
    server_name: String,
    verify: VerifyMode
  )
}

pub fn create_tls_options(config: TlsConfig) -> List(SslOption) {
  [
    {certfile, config.cert_file},
    {keyfile, config.key_file},
    {cacertfile, config.ca_file},
    {verify, verify_peer},
    {server_name_indication, config.server_name},
    {customize_hostname_check, [
      {match_fun, public_key:pkix_verify_hostname_match_fun(https)}
    ]}
  ]
}
```

### Certificate Rotation
```gleam
// poller/cert_watcher.gleam
pub fn start_cert_watcher(cert_files: List(String)) {
  actor.start_spec(actor.Spec(
    init: fn() {
      CertWatcher(
        cert_files: cert_files,
        last_modified: get_cert_mtimes(cert_files),
        connections: get_connection_managers()
      )
    },
    init_timeout: 2000,
    loop: handle_cert_message
  ))
}

pub fn handle_cert_message(
  message: CertMessage,
  state: CertWatcher
) -> actor.Next(CertWatcher) {
  case message {
    CheckCerts -> {
      current_mtimes = get_cert_mtimes(state.cert_files)

      case certs_modified(state.last_modified, current_mtimes) {
        True -> {
          // Trigger connection reconnection with new certs
          state.connections
          |> list.each(fn(conn) {
            conn |> actor.send(ReconnectWithNewCerts)
          })

          schedule_next_cert_check()
          actor.continue(CertWatcher(
            ..state,
            last_modified: current_mtimes
          ))
        }
        False -> {
          schedule_next_cert_check()
          actor.continue(state)
        }
      }
    }
  }
}
```

## Monitoring & Observability

### Metrics Collection
```gleam
// poller/metrics.gleam
pub type Metrics {
  Metrics(
    polls_total: Int,
    polls_successful: Int,
    polls_failed: Int,
    agent_connections: Int,
    agent_failures: Int,
    streaming_chunks_processed: Int,
    core_reports_sent: Int,
    hot_reloads: Int
  )
}

pub fn start_metrics_collector() {
  actor.start_spec(actor.Spec(
    init: fn() { Metrics(0, 0, 0, 0, 0, 0, 0, 0) },
    init_timeout: 1000,
    loop: handle_metrics_message
  ))
}

pub fn increment_poll_counter(result: PollResult) {
  metrics_collector |> actor.send(case result {
    Ok(_) -> IncrementSuccessful
    Error(_) -> IncrementFailed
  })
}
```

### Security Monitoring & Alerting

Following the security PoC patterns for comprehensive security monitoring:

```gleam
// security/monitoring.gleam
pub type SecurityEvent {
  NodeConnectionAttempt(node: Node, success: Bool, reason: String)
  CertificateValidationFailed(cert_cn: String, reason: String)
  UnauthorizedAccess(peer: String, requested_action: String)
  RateLimitExceeded(peer: String, current_rate: Int)
  MessageSignatureInvalid(sender: Node, reason: String)
  CertificateRotated(cert_cn: String)
  SecurityCircuitBreakerOpened(agent: String, failure_count: Int)
}

pub fn start_security_monitor() {
  use state <- gen_server.start_link()

  let state = SecurityMonitorState(
    events_buffer: queue.new(),
    alert_thresholds: load_alert_thresholds(),
    active_alerts: dict.new(),
  )

  // Set up telemetry handlers for security events
  telemetry.attach("security.connection.attempt",
    ["gleam", "security", "connection", "attempt"],
    handle_connection_attempt)

  telemetry.attach("security.auth.failure",
    ["gleam", "security", "auth", "failure"],
    handle_auth_failure)

  Ready(state)
}

pub fn log_security_event(event: SecurityEvent) {
  let event_data = security_event_to_json(event)

  // Structured logging for SIEM integration
  logger.info(event_data)

  // Real-time alerting for critical events
  case is_critical_event(event) {
    True -> send_security_alert(event)
    False -> Nil
  }

  // Update metrics
  update_security_metrics(event)
}

fn is_critical_event(event: SecurityEvent) -> Bool {
  case event {
    CertificateValidationFailed(_, _) -> True
    UnauthorizedAccess(_, _) -> True
    MessageSignatureInvalid(_, _) -> True
    SecurityCircuitBreakerOpened(_, _) -> True
    _ -> False
  }
}
```

### Security Metrics Integration

```gleam
// security/metrics.gleam
pub fn init_security_metrics() {
  // Connection security metrics
  telemetry.attach("security.connection.attempt",
    ["gleam", "security", "connection", "attempt"],
    fn(measurements, metadata, _config) {
      prometheus.counter_inc("security_connection_attempts_total", [
        #("result", case measurements.success { True -> "success"; False -> "failure" }),
        #("peer", metadata.peer_node),
      ])
    })

  // Authentication metrics
  telemetry.attach("security.auth.check",
    ["gleam", "security", "auth", "check"],
    fn(measurements, metadata, _config) {
      prometheus.histogram_observe("security_auth_check_duration_seconds",
        measurements.duration)

      prometheus.counter_inc("security_auth_checks_total", [
        #("result", case measurements.success { True -> "success"; False -> "failure" }),
        #("action", metadata.requested_action),
        #("peer", metadata.peer_cn),
      ])
    })

  // Certificate rotation metrics
  telemetry.attach("security.cert.rotation",
    ["gleam", "security", "cert", "rotation"],
    fn(_measurements, metadata, _config) {
      prometheus.counter_inc("security_cert_rotations_total", [
        #("cert_cn", metadata.cert_cn),
      ])
    })

  // Circuit breaker security metrics
  telemetry.attach("security.circuit_breaker.state_change",
    ["gleam", "security", "circuit_breaker", "state_change"],
    fn(_measurements, metadata, _config) {
      prometheus.counter_inc("security_circuit_breaker_state_changes_total", [
        #("agent", metadata.agent_name),
        #("new_state", metadata.new_state),
        #("reason", metadata.reason),
      ])
    })
}
```

### Health Checks with Security Context
```gleam
// poller/health.gleam
pub fn health_check_endpoint() -> Response {
  health_status = HealthStatus(
    status: get_overall_status(),
    agents: get_agent_statuses(),
    core_connection: get_core_connection_status(),
    security: get_security_status(),  // NEW: Security health
    uptime: get_uptime(),
    memory_usage: get_memory_usage(),
    process_count: get_process_count()
  )

  response.new(200)
  |> response.set_body(json.encode(health_status))
  |> response.set_header("content-type", "application/json")
}

pub fn get_security_status() -> SecurityStatus {
  SecurityStatus(
    certificates_valid: check_all_certificates_valid(),
    distribution_secure: check_distribution_security(),
    active_security_contexts: count_active_security_contexts(),
    recent_security_events: get_recent_security_events(300), // Last 5 minutes
    circuit_breakers_status: get_circuit_breakers_status(),
  )
}
```

## Expected Benefits

### Enhanced Security Benefits
- **Defense in depth**: Multiple security layers with BEAM process isolation
- **Zero-downtime certificate rotation**: Hot certificate reloading without service interruption
- **Security-aware circuit breakers**: Faster failure detection for security violations
- **Authenticated message passing**: All inter-service communication is signed and verified
- **RBAC enforcement**: Role-based access control at the process level
- **Security event monitoring**: Real-time security alerting and structured logging

### Fault Tolerance
- **Process isolation**: Agent failures won't affect other agents or security contexts
- **Supervision trees**: Automatic restart of failed components with security state preservation
- **Security-enhanced circuit breakers**: Built-in protection against both operational and security failures
- **Let-it-crash philosophy**: Simpler error handling and recovery with security context isolation

### Performance
- **Lightweight processes**: Millions of processes vs thousands of threads, each with isolated security context
- **Automatic backpressure**: GenStage prevents memory overflow while maintaining authentication
- **Hot code swapping**: Zero-downtime deployments including security logic updates
- **BEAM scheduler**: Optimal CPU utilization across cores with security processing overhead optimized

### Operational Excellence
- **Built-in debugging**: Observer, runtime introspection with security context visibility
- **Memory management**: Garbage collection per process including security state cleanup
- **Enhanced telemetry**: Native metrics and tracing support with comprehensive security monitoring
- **Rolling upgrades**: Code updates without service interruption including security policy updates
- **Security compliance**: Built-in audit logging and compliance reporting capabilities

This implementation plan provides a robust foundation for migrating the ServiceRadar poller to Gleam/BEAM while maintaining full compatibility with existing systems and achieving the operational benefits outlined in the PRD.